<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="嵌入推荐系统的协作知识库, SongX64">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>嵌入推荐系统的协作知识库 | SongX64</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.4.0"></head>



   <style>
    body{
       background-image: url(https://gitee.com/songx86/SongPicBed/raw/master/img/fd039245d688d43f5595595b7d1ed21b0ef43b5f.jpg);
       background-repeat:no-repeat;
       background-size:cover;
       background-attachment:fixed;
    }
</style>



<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">SongX64</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">SongX64</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/22.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">嵌入推荐系统的协作知识库</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/%E7%A7%91%E7%A0%94/">
                                <span class="chip bg-color">科研</span>
                            </a>
                        
                            <a href="/tags/Knowledge-Graph/">
                                <span class="chip bg-color">Knowledge Graph</span>
                            </a>
                        
                            <a href="/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/">
                                <span class="chip bg-color">论文翻译</span>
                            </a>
                        
                            <a href="/tags/Recommendation/">
                                <span class="chip bg-color">Recommendation</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E7%A7%91%E7%A0%94/" class="post-category">
                                科研
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-03-19
                </div>
                

                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    14.5k
                </div>
                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="嵌入推荐系统的协作知识库"><a href="#嵌入推荐系统的协作知识库" class="headerlink" title="嵌入推荐系统的协作知识库"></a>嵌入推荐系统的协作知识库</h1><h2 id="论文信息"><a href="#论文信息" class="headerlink" title="论文信息"></a>论文信息</h2><p>2016年</p>
<p>会议：<strong>ACM SIGKDD</strong>（知识发现与数据挖掘会议）<br>第22届ACM SIGKDD国际知识发现和数据挖掘会议论文集</p>
<h2 id="补充知识"><a href="#补充知识" class="headerlink" title="补充知识"></a>补充知识</h2><h3 id="1-异构图"><a href="#1-异构图" class="headerlink" title="1. 异构图"></a>1. 异构图</h3><p>同构图：在图里面，节点的类型和边的类型只有一种的图，举个例子，像社交网络中只存在一种节点类型，用户节点和一种边的类型，用户-用户之间的连边。</p>
<p>异构图：在图里面，节点的类型+边的类型&gt;2的一种图，举个例子，论文引用网络中，存在着作者节点和paper节点，边的关系有作者-作者之间的共同创作关系连边，作者-论文之间的从属关系，论文-论文之间的引用关系。</p>
<h3 id="2-TransR"><a href="#2-TransR" class="headerlink" title="2.TransR"></a>2.TransR</h3><p>知识图谱嵌入的Translate模型汇总（TransE，TransH，TransR，TransD）：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/147542008">https://zhuanlan.zhihu.com/p/147542008</a></p>
<p>然而，每个实体可以有许多方面，<strong>不同的关系关注实体的不同方面</strong>。例如，<code>(location, contains, location)</code>的关系是’contains’，<code>(person, born, date)</code>的关系是’born’。这<strong>两种关系非常不同</strong>。</p>
<p>为了解决这个问题，我们让TransR在两个不同的空间，即<strong>实体空间</strong>和<strong>多个关系空间</strong>(关系特定的实体空间)中建模实体和关系，并在对应的关系空间中进行转换，因此命名为TrandR。</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210323212540816.png" alt="image-20210323212540816"></p>
<p>TransR的基本思想如图1所示。<br>对于每个三元组(h, r, t)，<br>将实体空间中的<strong>实体通过矩阵Mr投影到r关系空间中，分别为hr和tr，</strong><br>然后有<strong>hr + r ≈ tr</strong>，损失函数和训练方法与TransE相同。<strong>h</strong>和<strong>t</strong>为实体嵌入，<strong>r</strong>为关系嵌入。</p>
<p>特定于关系的投影可以使实际持有这种关系的head/tail实体(表示为彩色圆圈)彼此靠近，同时那些不持有这个关系的实体相互远离(表示为彩色三角形)。</p>
<p>得分函数和目标函数与TransE相同。</p>
<blockquote>
<p>TransE的损失函数是使用了负抽样的max-margin函数。</p>
<p>L(y, y’) = max(0, margin - y + y’)</p>
<p><code>y</code>是正样本的得分，<code>y&#39;</code>是负样本的得分。然后使损失函数值最小化，当这两个分数之间的差距大于margin的时候就可以了(我们会设置这个值，通常是1)。</p>
<p>由于我们使用距离来表示得分，所以我们在公式中加上一个减号，知识表示的损失函数为：</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210323212639554.png" alt="image-20210323212639554"></p>
<p>其中，d是：</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210323212652208.png" alt="image-20210323212652208"></p>
<p>这是L1或L2范数。至于如何得到负样本，则是将head实体或tail实体替换为三元组中的随机实体。</p>
</blockquote>
<h3 id="3-关于自编码器"><a href="#3-关于自编码器" class="headerlink" title="3.关于自编码器"></a>3.关于自编码器</h3><ul>
<li>漫谈autoencoder：降噪自编码器/稀疏自编码器/栈式自编码器：<a target="_blank" rel="noopener" href="https://blog.csdn.net/wblgers1234/article/details/81545079">https://blog.csdn.net/wblgers1234/article/details/81545079</a></li>
<li>堆叠降噪自动编码器：<a target="_blank" rel="noopener" href="https://blog.csdn.net/zbzcDZF/article/details/86570761">https://blog.csdn.net/zbzcDZF/article/details/86570761</a></li>
</ul>
<h5 id="自编码器"><a href="#自编码器" class="headerlink" title="自编码器"></a>自编码器</h5><p>自编码器分为两个部分，编码器encoder和解码器decoder。一个单隐层的AE的网络结构如下图所示</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/20180811212403280" alt="img"></p>
<p>自编码器输出层的节点数与输入层相等。</p>
<p>值得注意的是，这种自编码器是一种<strong>不利用类标签的非线性特征提取方法</strong>， 就方法本身而言， 这种特征提取的<strong>目的在于保留和获得更好的信息表示</strong>， 而不是执行分类任务，尽管有时这两个目标是相关的。</p>
<p>自动编码机由三层网络组成，其中<strong>输入层</strong>神经元数量与<strong>输出层</strong>神经元数量相等，<strong>中间层</strong>神经元数量少于输入层和输出层。</p>
<p>搭建一个自动编码器需要完成下面三样工作：搭建编码器，搭建解码器，设定一个<strong>损失函数</strong>，用以衡量由于压缩而损失掉的信息（自编码器是有损的）。</p>
<p><strong>编码器和解码器</strong>一般都是<strong>参数化的方程</strong>，并关于损失函数可导，典型情况是使用神经网络。编码器和解码器的参数可以通过最小化损失函数而优化。</p>
<h5 id="降噪自编码器"><a href="#降噪自编码器" class="headerlink" title="降噪自编码器"></a>降噪自编码器</h5><p>和自编码器不同的是，降噪自编码的训练过程中，<strong>输入的数据有一部分是“损坏”的</strong>，DAE(Denoising Autoencoder)的核心思想是，一个能够从中恢复出原始信号的神经网络表达未必是最好的，<strong>能够对“损坏”的原始数据编码、解码，然后还能恢复真正的原始数据，这样的特征才是好的</strong>。在论文“Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion”中，阐述了DAE的原理，如下图所示：</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/20180811212442966" alt="img"></p>
<p>对于输入的数据x按照qD分布加入进行<strong>加噪“损坏”</strong>，</p>
<p>从图式可以看出，这个加噪过程是<strong>按照一定的概率（通常使用二项分布）将输入层的某些节点清0</strong>，然后将 $\hat x$ 作为自编码器的输入进行训练。</p>
<p><strong>除了对输入层数据的处理不同，其余部分DAE与AE完全类似</strong>。</p>
<h5 id="堆叠自编码器"><a href="#堆叠自编码器" class="headerlink" title="堆叠自编码器"></a>堆叠自编码器</h5><p>顾名思义，栈式自编码器就是<strong>多个自编码器级联</strong>，以完成逐层特征提取的任务，最终得到的特征更有代表性，并且维度很小。<br>栈式自编码器的训练过程是，n个AE按顺序训练，第1个AE训练完成后，将其编码器的输出作为第2个AE的输入，以此类推。最后得到的特征作为分类器的输入，完成最终的分类训练。如下四幅图所示：</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210323211120400.png" alt="image-20210323211120400"></p>
<h5 id="堆叠降噪自动编码器"><a href="#堆叠降噪自动编码器" class="headerlink" title="堆叠降噪自动编码器"></a>堆叠降噪自动编码器</h5><p>堆叠降噪自动编码器（Stacked Denoising Auto Encoder，SDAE）</p>
<p>SDAE的思想就是将多个DAE堆叠在一起形成一个深度的架构。只有<strong>在训练的时候才会对输入进行腐蚀(加噪)，训练完成就不需要在进行腐蚀</strong>。结构如下图所示：</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/20160823173106225" alt="img"></p>
<p><strong>逐层贪婪训练：</strong>每层自编码层都<strong>单独进行非监督训练</strong>，以最小化输入（输入为前一层的隐层输出）与重构结果之间的误差为训练目标。<br>前K层训练好了，就可以训练K+1层，因为已经前向传播求出K层的输出，再用K层的输出当作K+1的输入训练K+1层。<br>一旦SDAE训练完成, 其<strong>高层的特征</strong>就可以用做<strong>传统的监督算法的输入</strong>。当然，也可以在最顶层添加一层logistic regression layer（softmax层），然后使用带label的数据来进一步对网络进行<strong>微调（fine-tuning）</strong>，即用样本进行有监督训练。</p>
<hr>
<h3 id="4-评测指标MAP-K和Recall-K"><a href="#4-评测指标MAP-K和Recall-K" class="headerlink" title="4. 评测指标MAP@K和Recall@K"></a>4. 评测指标MAP@K和Recall@K</h3><p>MAP（Mean Average Precision）本是在信息检索领域用以衡量搜索引擎的排序性能的评价指标，对于推荐系统，可以将推荐列表视为一个排序列表。例如对于【命中，命中，未命中，未命中，未命中】和【未命中，未命中，未命中，命中，命中】这两个top-5的推荐列表，显然他们的precision都是 $\frac{2}{5} $    ，但是显然第一个推荐列表的性能要高于第二个推荐列表，因为其在第1、2位就已命中。<br>MAP的公式如下：</p>
<p>$$MAP@K=\frac{1}{\vert{U}\vert}\sum_{u=1}^{\vert{U}\vert}\frac{1}{min(m,K)}\sum_{k=1}^{min(n,K)}P(k)\cdot rel(k)$$</p>
<p>也可以这么理解：</p>
<p>$$AP@K=\frac{1}{min(m,K)}\sum_{k=1}^{min(n,K)}P(k)\cdot rel(k)$$</p>
<p>$$ MAP@K=\frac{1}{\vert{U}\vert}\sum_{u=1}^{\vert{U}\vert}AP@K $$</p>
<p>K是推荐列表的长度，如刚刚top-5的推荐列表里K就是5，$\vert{U}\vert$是用户的数量，m是用户实际选择的项目数，n是给用户推荐的项目数，P(k)指的是从推荐列表中排名第1的项目到排名第k的项目的precision，rel(k)表示排名第kk的项目是否被用户实际选择。<br>所以对于推荐列表【命中，命中，未命中，未命中，未命中】，假设该用户在测试集中实际选择了3个项目，则</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210331152517497.png" alt="image-20210331152517497"></p>
<p>而对于推荐列表【未命中，未命中，未命中，命中，命中】</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210331152543642.png" alt="image-20210331152543642"></p>
<hr>
<p>版权声明：本文为CSDN博主「百载文枢江左」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42690752/article/details/102827308">https://blog.csdn.net/weixin_42690752/article/details/102827308</a></p>
<hr>
<p>版权声明：本文为CSDN博主「百载文枢江左」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。<br>原文链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_42690752/article/details/102827308">https://blog.csdn.net/weixin_42690752/article/details/102827308</a></p>
<h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><p>在不同的推荐技术中，由于<strong>用户项交互的稀疏性</strong>，<strong>协同过滤</strong>通常遭受有限的性能。</p>
<p>要解决问题，通常使用辅助信息来提高性能。</p>
<p>由于网上信息的快速收集，<strong>知识库</strong>提供<strong>异构信息</strong>，包括具有不同语义的<strong>结构化和非结构化数据</strong>，可以由各种应用消耗。</p>
<p>在本文中，我们调查<strong>如何利用知识库中的异构信息来提高推荐系统的质量</strong>。</p>
<p>首先，通过利用知识库，我们设计<strong>三个组件</strong>以分别从<strong>结构内容，文本内容和视觉内容</strong>中提取项目的语义表示。</p>
<p>具体而言，我们采用异质网络嵌入(heterogeneous network embedding)方法称为<strong>TransR</strong>，通过考虑所述节点和关系的异质性来提取项目的结构表示。</p>
<p>我们应用<strong>堆叠的去噪自动编码器(stacked denoising auto-encoders)<strong>和</strong>堆叠的卷积自动编码器(stacked convolutional auto-encoders,)<strong>，它们是两种类型的基于深度学习的</strong>嵌入</strong>技术，以分别提取项目的<strong>文本表示</strong>和<strong>视觉表示</strong>。</p>
<p>最后，我们提出了我们的最终综合框架，被称为协作<strong>知识库嵌入（CKE）</strong>，共同学习协同过滤的潜在表示以及知识库的项目语义表示。</p>
<p>为了评估每个嵌入组件以及整个系统的性能，我们通过不同场景的两个RealWorld数据集进行广泛的实验。结果表明，我们的方法优于若干广泛采用的最先进的推荐方法。</p>
<h2 id="关键词"><a href="#关键词" class="headerlink" title="关键词"></a>关键词</h2><ul>
<li>推荐系统</li>
<li>知识库嵌入</li>
<li>协同联合学习</li>
</ul>
<h2 id="1-简介"><a href="#1-简介" class="headerlink" title="1.简介"></a>1.简介</h2><h4 id="协同过滤"><a href="#协同过滤" class="headerlink" title="协同过滤"></a>协同过滤</h4><h5 id="优点："><a href="#优点：" class="headerlink" title="优点："></a>优点：</h5><p>由于信息的爆炸性增长，推荐系统在在线服务中发挥着越来越重要的作用。在不同的推荐战略中，基于<strong>协同过滤（CF）使用历史互动或偏好</strong>的方法取得了重大成功[23]。</p>
<h5 id="缺点："><a href="#缺点：" class="headerlink" title="缺点："></a>缺点：</h5><p>然而，当<strong>用户项目交互非常稀疏</strong>时，CF方法通常会遭受有限的性能，这对于项目集非常大的在线购物等方案非常常见。<br>此外，CF方法<strong>不能推荐新项目</strong>，因为这些项目从未收到过去用户的任何反馈。</p>
<h5 id="解决："><a href="#解决：" class="headerlink" title="解决："></a>解决：</h5><p>为了解决这些问题，<strong>混合推荐系统，结合协同过滤和辅助信息</strong>，如物品内容，通常可以实现更好的推荐结果，并且近年来越来越受欢迎[2]。</p>
<h4 id="知识库"><a href="#知识库" class="headerlink" title="知识库"></a>知识库</h4><p>简介</p>
<p>在过去几年中，通过在统一的全球数据空间中的不同主题域中连接各种主题域名的各种信息，通过将各种信息与统一的全球数据空间中的不同主题域名连接各种信息，从而在链接数据原则上发布了越来越多的语义数据。这些异构数据互相链接，形成称为知识库的巨大信息资源库。已经建立了几个典型的知识库，包括Yago2，Nell3，DBPedia4和DeepDive5等学术项目，以及Microsoft的Satori6和Google知识图表7等商业项目。使用来自知识库的异构连接信息可以有助于开发关于难以从单个域的数据突出的问题的见解[6]。迄今为止，信息检索[9]，社区检测[25]，情绪分析[4] - 仅限名称 - 是成功利用知识库的值得注意的应用程序。</p>
<h4 id="混合推荐"><a href="#混合推荐" class="headerlink" title="混合推荐"></a>混合推荐</h4><p>实际上，由于知识库提供了丰富的信息，包括具有不同语义的结构化和非结构化数据，因此<strong>在混合推荐系统的上下文中使用知识库的使用</strong>是吸引了越来越多的关注。</p>
<h5 id="相关研究"><a href="#相关研究" class="headerlink" title="相关研究"></a>相关研究</h5><p>例如：</p>
<ul>
<li>yu等人。 [30]使用异构信息网络来表示知识库中的用户，项目，项目属性和互连关系。它们从网络结构中提取基于元路径的潜在特征，并应用基于贝叶斯排名优化的协同过滤，以解决实体推荐问题。</li>
<li>Grad-Gyenge等。通过采用基于扩展的激活技术来结合知识库的网络特征，扩展了协同过滤，用于推荐系统的额定预测任务。</li>
</ul>
<p>但是，以前的研究没有充分利用知识库的潜力，因为它们遭受以下限制：<br>1）仅利用知识库的单个网络结构信息，同时忽略诸如项目的文本和视觉信息的其他重要信号。<br>2）依靠繁重和繁琐的特征工程过程来提取知识库的特征。</p>
<h4 id="本文"><a href="#本文" class="headerlink" title="本文"></a>本文</h4><h5 id="提出方法："><a href="#提出方法：" class="headerlink" title="提出方法："></a>提出方法：</h5><p> 为了解决上述问题，请在本文中提出了一种新的推荐框架，<strong>将协同过滤与知识库中项目的不同语义表示集成</strong>。</p>
<p>对于知识库，除了<strong>网络结构信息</strong>，我们还考虑项目的<strong>文本内容</strong>和<strong>视觉内容</strong>（例如，电影的海报）。</p>
<p>为避免繁重和繁琐的手动特征提取，我们设计三个嵌入组件，以分别从<strong>知识库的结构内容，文本内容和视觉内容</strong>中提取项目的语义表示。</p>
<p>具体而言：</p>
<ol>
<li>我们首先通过考虑<strong>节点和关系的异质性</strong>来应用<strong>网络嵌入方法</strong>来提取<strong>项目的结构化表示</strong>。</li>
<li>接下来，我们采用<strong>堆叠的去噪自动编码器和堆叠的卷积自动编码器</strong>，这些自动编码器是两种类型的基于深度学习的嵌入技术，分别<strong>提取项目的文本表示和视觉表示</strong>。</li>
<li>最后，为了<strong>将协同过滤与知识库中的项目的语义表示顺利地融合</strong>，我们提出了我们的最终框架，该框架被称为嵌入（CKE）的协同知识库，以<strong>共同学习统一模型中的不同表示</strong>。</li>
</ol>
<h5 id="评估："><a href="#评估：" class="headerlink" title="评估："></a>评估：</h5><p>我们的实证研究包括多个部分。</p>
<p>首先，我们进行若干实验，以分别评估三个知识库嵌入组分的性能。</p>
<p>接下来，我们通过与若干竞争基线进行比较来评估我们的综合框架的有效性。</p>
<h5 id="主要贡献："><a href="#主要贡献：" class="headerlink" title="主要贡献："></a>主要贡献：</h5><p>本文的主要贡献总结如下：</p>
<ul>
<li>据我们所知，这是第一次将知识库中的<strong>结构化内容，文本内容，视觉信息</strong>用于推荐系统</li>
<li>我们应用嵌入方法，包括<strong>异构网络嵌入</strong>和<strong>深度学习嵌入</strong>，以自动提取知识库中的语义表示。<strong>学习的表示也可以用于推荐以外的任务。</strong></li>
<li> 通过<strong>共同执行知识库嵌入和协同过滤</strong>，CKE可以同时从知识库中提取特征表示，并捕获用户和项目之间的隐式关系</li>
<li> 根据两个实际数据集，我们对评估我们框架的有效性进行了广泛的实验。结果表明，我们的方法显着优于基线方法。</li>
</ul>
<h5 id="论文结构"><a href="#论文结构" class="headerlink" title="论文结构"></a>论文结构</h5><p>本文的其余部分安排如下。</p>
<p>第2节介绍了初步概念，并提出了我们的推荐问题。</p>
<p>第3节概述了我们的框架。</p>
<p>第4节删除了嵌入组件以提取知识库的表示。</p>
<p>在第5节中，我们讨论如何将协同过滤与嵌入统一模型的知识库有效地集成。</p>
<p>在第6节中讨论了经验结果，<br>然后简要介绍第7节中的相关工作，<br>并在第8节中结束了本文。</p>
<h2 id="2-初步概念"><a href="#2-初步概念" class="headerlink" title="2.初步概念"></a>2.初步概念</h2><p>在本节中，我们将首先澄清本文中使用的一些术语，然后明确呈现出我们的问题。</p>
<h3 id="2-1-用户隐反馈（User-Implicit-Feedback）"><a href="#2-1-用户隐反馈（User-Implicit-Feedback）" class="headerlink" title="2.1 用户隐反馈（User Implicit Feedback）"></a>2.1 用户隐反馈（User Implicit Feedback）</h3><p>本文考虑的推荐任务是针对<strong>隐性反馈</strong>的。</p>
<h4 id="隐反馈矩阵R"><a href="#隐反馈矩阵R" class="headerlink" title="隐反馈矩阵R"></a>隐反馈矩阵R</h4><p>假设有m个用户和n个项目，我们定义了<strong>用户隐含的反馈矩阵</strong> $R \in \mathbb{R}^{m\times n}$ 为：<br>$$<br>R = \begin{cases}<br>1, &amp; 如果已观察到(用户i,项目j)交互; \<br>0, &amp; 其余情况 \<br>\end{cases}<br>$$<br>其中矩阵R中的值1表示用户和项目之间的交互，例如，用户观看了电影或用户在搜索引擎中搜索了一本书。</p>
<p>请注意，隐式反馈数据中的<strong>值1并不意味着用户实际上喜欢这些项目</strong>。</p>
<p>实际上，用户搜索了一本书，因为他对这本书感兴趣，但在浏览互联网上的相关信息后，他可能可能不喜欢这本书。</p>
<p>同样，R中的<strong>值0并不意味着用户不喜欢这些项目</strong>，而是可以被视为<strong>负反馈的混合</strong>（用户对此类项目不感兴趣）和<strong>潜在的交互</strong>（用户不知道此类项目）。</p>
<blockquote>
<p><strong>只代表交互，不代表喜欢</strong></p>
</blockquote>
<h3 id="2-2-知识库-Knowledge-Base"><a href="#2-2-知识库-Knowledge-Base" class="headerlink" title="2.2 知识库(Knowledge Base)"></a>2.2 知识库(Knowledge Base)</h3><p>实际上，我们感兴趣的是利用知识库提高推荐系统的质量，因此<strong>推荐系统中的项目</strong>被<strong>映射到知识库中的实体</strong>（例如，电影项目通常可以映射到描述这部电影的实体），以及这些实体被称为本文中的<strong>项目实体</strong>。</p>
<h4 id="三个部分"><a href="#三个部分" class="headerlink" title="三个部分"></a>三个部分</h4><p>我们考虑存储在知识库中的信息可以分为<strong>三个部分：结构知识，文本知识和视觉知识</strong>。每个部分的详细定义如下：</p>
<h5 id="定义1：结构知识"><a href="#定义1：结构知识" class="headerlink" title="定义1：结构知识"></a>定义1：结构知识</h5><p>这些知识可以被视为具有<strong>多种类型的实体</strong>和<strong>多种类型的链路</strong>的异构网络，以表达知识库的结构。</p>
<p>对于电影推荐，<br>实体通常包括电影<strong>项目</strong>和相应属性（例如，类型“科学小说”和演员“Kevin Space”），<br>并且<strong>链接</strong>描述了这些实体（例如，“作用”行为和“评级”行为之间的关系 ）。</p>
<p>网络结构意味着<strong>项目实体之间的一些相似性</strong>，这对推荐<strong>最有用</strong>。</p>
<h5 id="定义2：文本知识"><a href="#定义2：文本知识" class="headerlink" title="定义2：文本知识"></a>定义2：文本知识</h5><p>对于知识库中的书籍或电影等项目实体，我们使用<strong>文本摘要</strong>来表示文本知识，通常为本书或这部电影提供了主要主题。</p>
<h5 id="定义3：视觉知识"><a href="#定义3：视觉知识" class="headerlink" title="定义3：视觉知识"></a>定义3：视觉知识</h5><p>对于项目实体，除了先前的文本描述外，知识库中通常存在一些图像，我们使用书的前<strong>封面图像</strong>或电影的<strong>海报图像</strong>来表示其视觉知识。</p>
<p><strong>用户隐式反馈交互</strong>和<strong>结构知识</strong>用作<strong>物品的结构特征</strong>，而文本知识和视觉知识则作为<strong>内容特征</strong>。</p>
<ul>
<li>物品的结构特征<ul>
<li>用户隐反馈交互</li>
<li>结构知识</li>
</ul>
</li>
<li>内容特征<ul>
<li>文本知识</li>
<li>视觉知识</li>
</ul>
</li>
</ul>
<p>图1中介绍了具有三种知识以及用户隐式反馈的知识库的片段。</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210319170822356.png" alt="image-20210319170822356"><br>图1：用户隐含反馈数据和知识库数据片段的例证</p>
<h3 id="2-3-问题描述"><a href="#2-3-问题描述" class="headerlink" title="2.3 问题描述"></a>2.3 问题描述</h3><p>我们在本文中定义了我们的推荐问题，如下所示：</p>
<p>给出具有结构知识的知识库，文本知识和视觉知识，以及用户隐含的反馈；</p>
<p>我们的目标是推荐给每个用户他会感兴趣的一个项目排行列表。</p>
<h2 id="3-综述"><a href="#3-综述" class="headerlink" title="3. 综述"></a>3. 综述</h2><p>在本文中，通过充分利用知识库中的结构知识，文本知识和视觉知识，我们提出了一个<strong>协作知识库嵌入模型（CKE）</strong>，以支持我们的推荐任务。</p>
<p>我们的模型主要由<strong>两个步骤</strong>组成：1）知识库嵌入2）协同联合学习。</p>
<h3 id="1-知识库嵌入"><a href="#1-知识库嵌入" class="headerlink" title="1)知识库嵌入"></a>1)知识库嵌入</h3><p>在知识库嵌入步骤中，我们分别从结构知识，文本知识和视觉知识中提取<strong>项目实体的三个嵌入向量</strong>。这些嵌入向量表示每个域中的项目实体的潜在表示。</p>
<p>对于<strong>结构嵌入</strong>组成部分，我们应用<strong>网络嵌入程序（贝叶斯TransR）</strong>从结构化的知识的异构网络中找到潜在的表现。</p>
<p>对于<strong>文本嵌入</strong>组件，我们应用一个叫做<strong>贝叶斯堆积的去噪自动编码器（Bayesian SDAE）</strong>的无监督的深度学习模型[29]以找到文本知识的潜在表示。</p>
<p>同样，我们应用另一个叫做<strong>贝叶斯堆积的卷积自动编码器（贝叶斯SCAE）</strong>的无监督的深度学习模型，以找到<strong>视觉知识</strong>的潜在表示。</p>
<h3 id="2-协同联合学习"><a href="#2-协同联合学习" class="headerlink" title="2)协同联合学习"></a>2)协同联合学习</h3><p>在协作联合学习步骤中，最终将<strong>项目的潜在矢量</strong>表示为从知识库和潜在偏移量载体的<strong>三个嵌入向量的集成</strong>。</p>
<p>最终项目潜伏载体代表了来自结构内容，文本内容，视觉内容以及历史(用户-项目)交互的项目的知识。</p>
<p>然后，我们通过<strong>优化项目之间的成对排名</strong>来使用<strong>协同过滤</strong>来学习用户潜在向量和项目潜在的向量。</p>
<p>最终推荐由这些<strong>用户潜在的向量</strong>和<strong>项目潜在的向量</strong>生成。</p>
<p>我们框架的流程图如图2所示。<strong>知识库嵌入</strong>和<strong>协作联合学习</strong>将分别在第4节和第5节中详细说明。</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210319172248054.png" alt="image-20210319172248054"></p>
<p>图2：协同知识库嵌入（CKE）框架的推荐系统流程图</p>
<h2 id="4-知识库嵌入"><a href="#4-知识库嵌入" class="headerlink" title="4.知识库嵌入"></a>4.知识库嵌入</h2><p>在本节中，通过利用网络嵌入和深度学习嵌入，我们介绍了我们如何分别从结构知识，文本知识和视觉知识中提取项目实体的表现。</p>
<h3 id="4-1-结构化嵌入"><a href="#4-1-结构化嵌入" class="headerlink" title="4.1 结构化嵌入"></a>4.1 结构化嵌入</h3><p>异构网络编码实体的结构化信息及其丰富关系。</p>
<p>为了捕获这种<strong>结构化知识</strong>，希望将该<strong>异构网络嵌入</strong>到连续的矢量空间中，同时保留网络的某些信息。</p>
<p>在本小节中，我们首先简要介绍一个名为<strong>TransR</strong> [15]的最新的网络嵌入方法，然后为我们的任务给出TransR的贝叶斯表达。</p>
<p>首先，要代表结构知识，我们使用一个<strong>无向图</strong>$G =（V，E）$，<br>其中$V = { v_1,……v_{|V|} }$是一组<strong>顶点</strong>，指的是<strong>不同实体</strong>，<br>E是一组<strong>边</strong>，参考这些实体之间的不同类型的<strong>关系</strong>。</p>
<p>Transr [15]是用于异构网络的最先进的嵌入方法。</p>
<p>与承担相同空间RK内的实体和关系的其他方法不同，Transr表示由关系特定矩阵桥接的不同语义空间中的实体和关系。</p>
<p>在Transr中，对于网络中的每个三元组$（v_h，r，v_t）$，（$v_h$和$v_t$是两个链接实体，r是它们之间的边类型），实体嵌入到向量$v_h,v_t \in \mathbb R^k$中，而关系嵌入到$r \in \mathbb R^d$中。</p>
<ul>
<li>三元组：$（v_h，r，v_t）$</li>
<li>实体嵌入：$v_h,v_t \in \mathbb R^k$</li>
<li>关系嵌入：$r \in \mathbb R^d$</li>
</ul>
<p>对于每个<strong>关系</strong>r，我们设置了一个<strong>投影矩阵</strong>$M_r \in \mathbb R ^{k \times d}$，其将来自实体空间的<strong>实体项目</strong>投影到<strong>关系空间</strong>。</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210319183246177.png" alt="image-20210319183246177"></p>
<p>图3：结构化嵌入TransR的例子</p>
<p>如图3所示，项目的<strong>实体向量</strong>被定义为</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210319180730045.png" alt="image-20210319180730045"></p>
<p>这个三元组的的评分函数相应定义为:</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210319180747181.png" alt="image-20210319180747181"></p>
<h4 id="生成过程，TransR的贝叶斯版本"><a href="#生成过程，TransR的贝叶斯版本" class="headerlink" title="生成过程，TransR的贝叶斯版本"></a>生成过程，TransR的贝叶斯版本</h4><p>类似于[22]，我们使用<code>sigmod</code>函数来计算成对三元组排名概率，而不是原始Transr中采用的（margin-based objective function）基于边缘的目标函数。然后我们将TransR延伸到贝叶斯版本，并提出了如下的生成过程：</p>
<ol>
<li>对于每个实体v，使得$v \sim N(0, \lambda_v^{-1}I)$</li>
<li>对于每个关系r，分别使得$r \sim N(0, \lambda_r^{-1}I)$  和$M_r \sim N(0, \lambda_M^{-1}I)$</li>
<li>对于每个四元组$(v_h,r,v_t,v_t’) \in S$ ，从概率$\sigma (f_r(v_h,v_t) - f_r(v_h,v_t’))$使得，其中S是满足的一下条件的四元组集合：$（v_h,r,v_t）$ 是一个正确的三元组，$(v_h,r,v_t’)$是一个不正确的三元组。$\sigma :(x) = {1 \over 1+e^{-x}} $ 是逻辑sigmoid函数</li>
</ol>
<p>对于正确的三元组$（v_h，r，v_t）$来说，通过将一个实体用相同类型的另一个实体来替换是很常见的，并且构造不正确的三倍$（v_h，r，v_{t’}）$。</p>
<p>注意，步骤3意味着当正确三元组的得分函数大于不正确的三元组的分数函数时，可以更容易采样四元组。</p>
<p>对于每个项目实体$j$，我们使用贝叶斯TransR嵌入向量$v_j$来代表其结构化表示。</p>
<blockquote>
<p>TransR需要深♂入了解一下</p>
</blockquote>
<hr>
<p>知识图谱嵌入的Translate模型汇总（TransE，TransH，TransR，TransD）：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/147542008">https://zhuanlan.zhihu.com/p/147542008</a></p>
<h4 id="关于TransR"><a href="#关于TransR" class="headerlink" title="关于TransR"></a>关于TransR</h4><p>然而，每个实体可以有许多方面，<strong>不同的关系关注实体的不同方面</strong>。例如，<code>(location, contains, location)</code>的关系是’contains’，<code>(person, born, date)</code>的关系是’born’。这<strong>两种关系非常不同</strong>。</p>
<p>为了解决这个问题，我们让TransR在两个不同的空间，即<strong>实体空间</strong>和<strong>多个关系空间</strong>(关系特定的实体空间)中建模实体和关系，并在对应的关系空间中进行转换，因此命名为TrandR。</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210323212540816.png" alt="image-20210323212540816"></p>
<p>TransR的基本思想如图1所示。<br>对于每个三元组(h, r, t)，<br>将实体空间中的<strong>实体通过矩阵Mr投影到r关系空间中，分别为hr和tr，</strong><br>然后有<strong>hr + r ≈ tr</strong>，损失函数和训练方法与TransE相同。<strong>h</strong>和<strong>t</strong>为实体嵌入，<strong>r</strong>为关系嵌入。</p>
<p>特定于关系的投影可以使实际持有这种关系的head/tail实体(表示为彩色圆圈)彼此靠近，同时那些不持有这个关系的实体相互远离(表示为彩色三角形)。</p>
<p>得分函数和目标函数与TransE相同。</p>
<blockquote>
<p>TransE的损失函数是使用了负抽样的max-margin函数。</p>
<p>L(y, y’) = max(0, margin - y + y’)</p>
<p><code>y</code>是正样本的得分，<code>y&#39;</code>是负样本的得分。然后使损失函数值最小化，当这两个分数之间的差距大于margin的时候就可以了(我们会设置这个值，通常是1)。</p>
<p>由于我们使用距离来表示得分，所以我们在公式中加上一个减号，知识表示的损失函数为：</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210323212639554.png" alt="image-20210323212639554"></p>
<p>其中，d是：</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210323212652208.png" alt="image-20210323212652208"></p>
<p>这是L1或L2范数。至于如何得到负样本，则是将head实体或tail实体替换为三元组中的随机实体。</p>
</blockquote>
<h3 id="4-2-文本嵌入"><a href="#4-2-文本嵌入" class="headerlink" title="4.2 文本嵌入"></a>4.2 文本嵌入</h3><p>在本小节中，我们调查如何应用一个名为<strong>堆叠去噪自动编码器（SDAE）</strong>的<strong>无监督深度学习</strong>模型，以获取文本知识的项目实体的文本表示。</p>
<h4 id="4-2-1符号表示"><a href="#4-2-1符号表示" class="headerlink" title="4.2.1符号表示"></a>4.2.1符号表示</h4><p>SDAE [27]是用于学习损坏的输入数据表示的反馈神经网络，通过学习预测输出中的清洁本身。</p>
<p>在提出模型细节之前，我们提供SDAE中使用的符号。</p>
<p>假设网络层的数量是$L_t$，我们使用矩阵$X_l$代表SDAE中的第L层的输出。</p>
<p>请注意，我们使用最后一层输出 <strong>$X_{L_t}$ 来表示所有项目实体的原始清洁文本知识</strong>，其中第j行是实体j的词袋矢量$X_{L_{t,j*}}$，j * 。</p>
<p>同样，我们使用<strong>矩阵$X_0$来表示噪声损坏的矩阵</strong>（随机掩蔽了$X_{L_t}$的某些实体，通过使其为0的方式）。</p>
<p><strong>$W_l$ 和 $b_l$ 分别是用于l层的权重参数和偏置参数。</strong></p>
<h4 id="4-2-2图示"><a href="#4-2-2图示" class="headerlink" title="4.2.2图示"></a>4.2.2图示</h4><p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210323201237435.png" alt="image-20210323201237435"><br>图4：用于文本嵌入的6层SDAE的图示</p>
<p>图4给出了一个6层SDAE的例证，用于我们的文本嵌入组件。</p>
<p>如该图所示，网络的第一个$L_t \over 2$ 层（从$X_0$ 到 $X_3$）通常用作编码器部分，该部分将损坏的输入$X_0$映射到潜在的紧凑型表示$X_3$，并且最后一个$L_t \over 2$ 层（从$X_3$ 到 $X_6$）通常用作解码器部分，其恢复清洁输入X6的潜在表示X3。</p>
<h4 id="4-2-3-贝叶斯SDAE中每层L的生成过程"><a href="#4-2-3-贝叶斯SDAE中每层L的生成过程" class="headerlink" title="4.2.3 贝叶斯SDAE中每层L的生成过程"></a>4.2.3 贝叶斯SDAE中每层L的生成过程</h4><p>与[29]类似，同时给出观测到的清洁输入$X_{L_t}$和损坏的输入$X_0$，我们介绍了贝叶斯SDAE中每层L的生成过程，如下所示：</p>
<ol>
<li>对于给定的权重参数$W_l$，使得$W_l \sim N(0, \lambda_W^{-1}I)$</li>
<li>对于偏重参数，使得$b_l \sim N(0, \lambda_b^{-1}I)$ </li>
<li>对于此层的输出，使得$X_l \sim N(\sigma (X_{l-1} W_l + b_l), \lambda_X^{-1}I)$</li>
</ol>
<p>中间层中的嵌入矢量，比如图4中的$X_{3,j*}$  ，被用作项目实体j的文本表示。</p>
<hr>
<h4 id="4-2-4-关于自编码器"><a href="#4-2-4-关于自编码器" class="headerlink" title="4.2.4 关于自编码器"></a>4.2.4 关于自编码器</h4><ul>
<li>漫谈autoencoder：降噪自编码器/稀疏自编码器/栈式自编码器：<a target="_blank" rel="noopener" href="https://blog.csdn.net/wblgers1234/article/details/81545079">https://blog.csdn.net/wblgers1234/article/details/81545079</a></li>
<li>堆叠降噪自动编码器：<a target="_blank" rel="noopener" href="https://blog.csdn.net/zbzcDZF/article/details/86570761">https://blog.csdn.net/zbzcDZF/article/details/86570761</a></li>
</ul>
<h5 id="自编码器-1"><a href="#自编码器-1" class="headerlink" title="自编码器"></a>自编码器</h5><p>自编码器分为两个部分，编码器encoder和解码器decoder。一个单隐层的AE的网络结构如下图所示</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/20180811212403280" alt="img"></p>
<p>自编码器输出层的节点数与输入层相等。</p>
<p>值得注意的是，这种自编码器是一种<strong>不利用类标签的非线性特征提取方法</strong>， 就方法本身而言， 这种特征提取的<strong>目的在于保留和获得更好的信息表示</strong>， 而不是执行分类任务，尽管有时这两个目标是相关的。</p>
<p>自动编码机由三层网络组成，其中<strong>输入层</strong>神经元数量与<strong>输出层</strong>神经元数量相等，<strong>中间层</strong>神经元数量少于输入层和输出层。</p>
<p>搭建一个自动编码器需要完成下面三样工作：搭建编码器，搭建解码器，设定一个<strong>损失函数</strong>，用以衡量由于压缩而损失掉的信息（自编码器是有损的）。</p>
<p><strong>编码器和解码器</strong>一般都是<strong>参数化的方程</strong>，并关于损失函数可导，典型情况是使用神经网络。编码器和解码器的参数可以通过最小化损失函数而优化。</p>
<h5 id="降噪自编码器-1"><a href="#降噪自编码器-1" class="headerlink" title="降噪自编码器"></a>降噪自编码器</h5><p>和自编码器不同的是，降噪自编码的训练过程中，<strong>输入的数据有一部分是“损坏”的</strong>，DAE(Denoising Autoencoder)的核心思想是，一个能够从中恢复出原始信号的神经网络表达未必是最好的，<strong>能够对“损坏”的原始数据编码、解码，然后还能恢复真正的原始数据，这样的特征才是好的</strong>。在论文“Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion”中，阐述了DAE的原理，如下图所示：</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/20180811212442966" alt="img"></p>
<p>对于输入的数据x按照qD分布加入进行<strong>加噪“损坏”</strong>，</p>
<p>从图式可以看出，这个加噪过程是<strong>按照一定的概率（通常使用二项分布）将输入层的某些节点清0</strong>，然后将 $\hat x$ 作为自编码器的输入进行训练。</p>
<p><strong>除了对输入层数据的处理不同，其余部分DAE与AE完全类似</strong>。</p>
<h5 id="堆叠自编码器-1"><a href="#堆叠自编码器-1" class="headerlink" title="堆叠自编码器"></a>堆叠自编码器</h5><p>顾名思义，栈式自编码器就是<strong>多个自编码器级联</strong>，以完成逐层特征提取的任务，最终得到的特征更有代表性，并且维度很小。<br>栈式自编码器的训练过程是，n个AE按顺序训练，第1个AE训练完成后，将其编码器的输出作为第2个AE的输入，以此类推。最后得到的特征作为分类器的输入，完成最终的分类训练。如下四幅图所示：</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210323211120400.png" alt="image-20210323211120400"></p>
<h5 id="堆叠降噪自动编码器-1"><a href="#堆叠降噪自动编码器-1" class="headerlink" title="堆叠降噪自动编码器"></a>堆叠降噪自动编码器</h5><p>堆叠降噪自动编码器（Stacked Denoising Auto Encoder，SDAE）</p>
<p>SDAE的思想就是将多个DAE堆叠在一起形成一个深度的架构。只有<strong>在训练的时候才会对输入进行腐蚀(加噪)，训练完成就不需要在进行腐蚀</strong>。结构如下图所示：</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/20160823173106225" alt="img"></p>
<p><strong>逐层贪婪训练：</strong>每层自编码层都<strong>单独进行非监督训练</strong>，以最小化输入（输入为前一层的隐层输出）与重构结果之间的误差为训练目标。<br>前K层训练好了，就可以训练K+1层，因为已经前向传播求出K层的输出，再用K层的输出当作K+1的输入训练K+1层。</p>
<p>一旦SDAE训练完成, 其<strong>高层的特征</strong>就可以用做<strong>传统的监督算法的输入</strong>。当然，也可以在最顶层添加一层logistic regression layer（softmax层），然后使用带label的数据来进一步对网络进行<strong>微调（fine-tuning）</strong>，即用样本进行有监督训练。</p>
<hr>
<h3 id="4-3视觉嵌入"><a href="#4-3视觉嵌入" class="headerlink" title="4.3视觉嵌入"></a>4.3视觉嵌入</h3><p>在这个小节中，类似于以前的文本嵌入部分，我们应用另一个无监督的深度学习模型，称为<strong>堆叠卷积自动编码器（SCAE）</strong>，以从视觉知识中提取项目实体的语义表示。</p>
<p>对于视觉对象，基于卷积的深度学习架构通常会击败公共完全连接的架构，因为<strong>它们可以在潜在的更高级别特征表示中保留图像的邻域关系和空间位置</strong>[7]。<br>此外，卷积层通过<strong>共享权重</strong>来限制自由参数的数量，使得它们对高维图像内容进行比较。<br>如上所述，通过在[16]的工作之后，<strong>我们通过使用卷积隐藏层采用堆叠的卷积自动编码器（SCAE）来替换先前SDAE中的完全连接的层</strong>。</p>
<h4 id="4-3-1-符号表示"><a href="#4-3-1-符号表示" class="headerlink" title="4.3.1 符号表示"></a>4.3.1 符号表示</h4><p>假设SCAE中有$L_v$层，类似于SDAE中的符号，我们使用4维张量**$Z_{L_v}$表示清洁图像的集合<strong>，其中第j行是一个三维张量 $Z_{L_{v , j*}}$，代表实体j 在RGB颜色空间中的原始像素表示。同样，我们使用</strong>$Z_0$来表示损坏的图像<strong>（通过添加高斯噪声随机掩蔽了一些实体$Z_l$）。<br>接下来，对于每层L，我们使用</strong>$Z_l$表示输出，$Q_l$表示权重参数，并且$c_l$表示偏置参数。**</p>
<h4 id="4-3-2-插图"><a href="#4-3-2-插图" class="headerlink" title="4.3.2 插图"></a>4.3.2 插图</h4><p>在SCAE中，我们将第 ${L_v} \over 2$ 层和第${ {L_v} \over 2 } +1$ 层设置为完全连接的层，而其他层作为卷积层。</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326101411313.png" alt="image-20210326101411313"><br>                                                                        图5：视觉嵌入的6层SCAE的例子</p>
<p>图5给出了6层SCAE的插图，也包括编码器部分和解码器部分。</p>
<p>如图所示，编码器部分由两个卷积层（从Z_0到Z_2）和完全连接的层（Z_2到Z_3）组成。<br>类似地，解码器部分由完全连接的层（Z3到Z4）和两个以下的碎屑层（从Z4到Z6）组成。<br>请注意，中间隐藏层的输出Z_3是一个矩阵，其表示所有项目实体的视觉嵌入向量的集合。而其他隐藏层的输出通常被称为特征映射[7]，是生成的4维张量来自卷积层。卷积层的映射如下给出:</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326101202160.png" alt="image-20210326101202160"></p>
<p>其中*表示卷积操作，可以保留先前输出的本地连接度。有关卷积运算符的更多细节可以参考[20]。</p>
<h4 id="4-2-3-贝叶斯SCAE每层L的生成过程"><a href="#4-2-3-贝叶斯SCAE每层L的生成过程" class="headerlink" title="4.2.3 贝叶斯SCAE每层L的生成过程"></a>4.2.3 贝叶斯SCAE每层L的生成过程</h4><p>与文本嵌入组件类似，给定清洁图像输入$Z_{L_v}$ 和加噪的输入$Z_0$，我们介绍了贝叶斯SCAE中每层L的生成过程，如下所示：</p>
<ol>
<li>对于给定的权重参数，使得$Q_l \sim N(0, \lambda_Q^{-1}I)$</li>
<li>对于偏重参数，使得$c_l \sim N(0, \lambda_c^{-1}I)$ </li>
<li>对于此层的输出，<ol>
<li>如果 l 层是一个全连接层，使得$Z_l \sim N(\sigma (Z_{l-1} Q_l + c_l), \lambda_Z^{-1}I)$</li>
<li>否则，使得$Z_l \sim N(\sigma (Z_{l-1}*Q_l + c_l), \lambda_Z^{-1}I)$</li>
</ol>
</li>
</ol>
<blockquote>
<p>这里*是卷积运算符？</p>
</blockquote>
<p>中间层中的嵌入矢量，比如图5中的$Z_{3,j*}$，用作项目实体j的视觉表示。</p>
<h2 id="5-协同联合学习"><a href="#5-协同联合学习" class="headerlink" title="5.协同联合学习"></a>5.协同联合学习</h2><p>在本节中，为了将<strong>协同过滤与知识库中项目的嵌入式</strong>筛选集成，我们提出了CKE框架中的<strong>协同联合学习程序</strong>。</p>
<p>给定用户隐含的反馈R，由[22]的动机，为了学习相似度我们考虑了物品之间的成对排名。</p>
<p>更具体的是，当$R_{ij} = 1$而$R_{ij’} = 0$ 时，我们说用户 i 更喜欢物品 j 超过物品 j’ ，然后使用 $p（j&gt; j  ; i | θ）$ 来表示一对偏好概率，其中θ表示模型参数。</p>
<p><strong>在协同过滤中，我们使用潜在的矢量 $u_i$ 作为 用户i 的表示，以及潜在向量$\eta _j $ 作为 项目j 的表示。</strong></p>
<p>为了同时捕获在<strong>协同过滤</strong>中item的<strong>潜在表示</strong>，与在item在<strong>知识库中的表示</strong>，<strong>item的潜在向量</strong>可以重新表示为：</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326104621075.png" alt="image-20210326104621075"></p>
<p>然后可以给予成对偏好概率</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326104918314.png" alt="image-20210326104918314"></p>
<p><strong>在知识库中使用Bayesian Transr，Bayesian SDAE和Bayesian Scae作为组件的嵌入步骤，我们使用协同加入学习的框架CKE的生成过程如下</strong>：</p>
<ol>
<li>考虑结构化的知识：<ol>
<li>对于每个实体v，使得$v \sim N(0, \lambda_v^{-1}I)$</li>
<li>对于每个关系r，分别使得$r \sim N(0, \lambda_r^{-1}I)$  和$M_r \sim N(0, \lambda_M^{-1}I)$</li>
<li>对于每个四元组$(v_h,r,v_t,v_t’) \in S$ ，从概率$\sigma (f_r(v_h,v_t) - f_r(v_h,v_t’))$使得，其中S是满足的一下条件的四元组集合：$（v_h,r,v_t）$ 是一个正确的三元组，$(v_h,r,v_t’)$是一个不正确的三元组。$\sigma :(x) = {1 \over 1+e^{-x}} $ 是逻辑sigmoid函数</li>
</ol>
</li>
<li>考虑文本化知识，对于SDAE中的每层：<ol>
<li>对于给定的权重参数$W_l$，使得$W_l \sim N(0, \lambda_W^{-1}I)$</li>
<li>对于偏重参数，使得$b_l \sim N(0, \lambda_b^{-1}I)$ </li>
<li>对于此层的输出，使得$X_l \sim N(\sigma (X_{l-1} W_l + b_l), \lambda_X^{-1}I)$</li>
</ol>
</li>
<li>考虑视觉知识，对于SCAE中的每层：<ol>
<li>对于给定的权重参数，使得$Q_l \sim N(0, \lambda_Q^{-1}I)$</li>
<li>对于偏重参数，使得$c_l \sim N(0, \lambda_c^{-1}I)$ </li>
<li>对于此层的输出，<ol>
<li>如果 l 层是一个全连接层，使得$Z_l \sim N(\sigma (Z_{l-1} Q_l + c_l), \lambda_Z^{-1}I)$</li>
<li>否则，使得$Z_l \sim N(\sigma (Z_{l-1}*Q_l + c_l), \lambda_Z^{-1}I)$</li>
</ol>
</li>
</ol>
</li>
<li>对于每个item j，使得一个潜在item偏移向量 $\eta _j \sim N(0, \lambda_I^{-1}I)$ ，之后将 item 的潜在向量设为：<br><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326104621075.png" alt="image-20210326104621075"></li>
<li>对于每个用户i，使得一个用户的潜在向量为$u_i \sim N(0, \lambda_U^{-1}I)$ </li>
<li>对于每个三元组 $(i,j,j’) \in D$ ，使得其概率 $\sigma(u_{i}^Te_j - u_{i}^Te_{j’})$ </li>
</ol>
<p>在这里，D是一系列的三元组，其中每个三联（i，j，j’）满足$R_{ij} = 1$而$R_{ij’} = 0$ （j’是从用户i的不感兴趣的item中随机采样）。请注意，$X_{ {L_t \over 2},j*}$ 和 $X_{ {L_v \over 2},j*}$ 分别用作隐式反馈偏好和结构知识，文本知识以及视觉知识之间的桥梁</p>
<p><strong>学习参数</strong>。计算参数的完整后部是棘手的。与[28]相同，最大化u，e，r，M，W，b，Q和c的后验概率，是等价于最大化对数似然函数，如下：</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326110639785.png" alt="image-20210326110639785"></p>
<p>最大化EQ的目标。 （7），我们采用类似于[22]的随机梯度下降（SGD）算法。<br>在每次迭代中，对于一个随机采样的三元组（i，j，j’）∈D，我们找到子集$S_{j,j’} \in S$ 满足$S_{j,j’}$ 中的的每个四元组包含项目j或项目j’。然后，我们使用相应的目标函数的梯度对每个参数进行SGD更新[10]。</p>
<p>预测 用户i 的最终项目推荐根据以下排名标准给出：</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326111058340.png" alt="image-20210326111058340"></p>
<h2 id="6-实验"><a href="#6-实验" class="headerlink" title="6.实验"></a>6.实验</h2><p>在本节中，我们评估我们在两个RealWorld数据集中的建议框架，适用于两部电影和书籍推荐方案。实验结果表明了许多竞争基础的显着改善的证据。</p>
<h3 id="6-1-数据集描述"><a href="#6-1-数据集描述" class="headerlink" title="6.1 数据集描述"></a>6.1 数据集描述</h3><p>为了展示拟议的协作知识库嵌入建议框架的有效性，我们使用来自不同域名（电影和书籍）的两个数据集进行实证研究。</p>
<p>第一个DataSet <a target="_blank" rel="noopener" href="http://grouplens.org/datasets/movielens/1m/">Movielens-1M</a>，由1M等级组成，6,040名用户和3,706部电影。</p>
<p>与[31]类似，为了与隐性反馈设置一致，我们仅提取积极的评分（评分5）以进行培训和测试。除了较少3次阳性额定值的用户后，我们有5,883名用户，3,230部电影和226,101个额定值在最终数据集中。</p>
<p>从Microsoft的Bing搜索引擎和Microsoft的Satori知识库中收集了作为IntentBooks的第二个数据集[1]。</p>
<p>在此数据集中，用户对书籍的兴趣从单击/查询操作中提取，例如，如果用户对“哈利波特”或单击包含该名称的文档进行查询，则此用户可能对相关的簿籍实体感兴趣。</p>
<p>为了减少名称冲突问题（例如，而不是书籍，“哈利波特”实际上可能意味着相关的电影），我们通过将无监督的相似性计算与通过以下[13]结合监督分类来提取用户的书籍兴趣。</p>
<p>此外，为了验证书籍兴趣提取的有效性，我们随机选择了200个提取的书籍兴趣实例并手动标记为真或假。</p>
<p>结果表明，精度为91.5％，我们认为对后续实验足够准确。</p>
<p>我们从Bing的搜索日志中对用户进行隐式反馈数据进行示例，时间是从2014年9月到2015年6月期间的。删除少于5本书兴趣的用户，我们终于拥有92,564名用户，18,475本书和897,871个用户-数据兴趣关系。</p>
<p>我们还使用Satori知识库来提取这两个数据集的结构知识，文本知识和视觉知识。</p>
<p>首先，我们应用了[24]中描述的两个分阶段方法（包括标题匹配和属性匹配），将来自Movielens-1M数据集的每个电影映射到知识库中的实体（请注意，Intentbooks DataSet中的一本书已经是一个知识库中的实体，因此匹配步骤忽略）。</p>
<p>我们明确地观察到200个配对结果，其中92％的对正确匹配（匹配精度足够好，以便以后的过程）。</p>
<p>此外，我们发现只有134部电影无法映射到知识库中的任何电影实体。</p>
<p>接下来，为了构建结构知识，我们从知识库中提取一个子图，其中包含项目实体的实体，距离项目实体的一个实体，以及相应的关系。</p>
<p>对于电影实体，1步实体包括流派，导演，作家，演员，语言，国家，生产日期，评级，提名奖和获得奖项;对于书籍实体，1步实体包括流派，作者，发布日期，属于系列，语言和评级。</p>
<p>然后用于文本知识，我们遵循哈希程序单词，如[12]中的散列程序，以预处理从电影的情节中提取的文本信息和书籍的描述。</p>
<p>最后，为了视觉知识，我们使用电影实体的海报图像和书籍实体的前封面图像，其中最终使用的视觉输入是在RGB空间中重塑到3×64×64张量格式的图像。</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326112752235.png" alt="image-20210326112752235"></p>
<p>表1中总结了两个数据集的一些详细统计信息。<br>例如，“#sk节点”表示提取的结构知识中的节点总数，<br>“#tk项目”表示具有文本知识的项目数量<br>“#VK项目“表示具有视觉知识的项目数。</p>
<h3 id="6-2-评估标准"><a href="#6-2-评估标准" class="headerlink" title="6.2 评估标准"></a>6.2 评估标准</h3><p>如[19]所述，精度不是隐式反馈推荐的合适性能措施。</p>
<p>因此，在我们的实验中，我们使用MAP@K（意思是平均精度）[26] 和 Recall@K 评估Top-K推荐的性能。</p>
<p>对于每个数据集，类似于[14]，我们随机选择与每个用户关联的<strong>70％</strong>项目，以构成<strong>训练集</strong>，并使用所有剩余的<strong>测试集</strong>。</p>
<p>对于每个评估方案，我们<strong>使用不同随机选择的训练集重复五次评估</strong>，并且在以下部分中报告了平均性能。</p>
<p>对于每个数据集，我们还使用从训练集中设置的验证，以查找我们的方法的<strong>最佳超参数</strong>以及在以后的零件中引入的<strong>基线</strong>。</p>
<p>在以下报告的结果中，我们的方法的<strong>超参数</strong>设置在表2中给出，因为实现了最佳性能。</p>
<p>在表2中，</p>
<ul>
<li>DIM表示潜在的维度，</li>
<li>$\epsilon$表示噪声屏蔽级别，</li>
<li>$\sigma$ 代表图像的高斯滤波器噪声的标准偏差， </li>
<li>$L_t$ 和 $L_v$ 代表层数，</li>
<li>$N_l$ 代表在文本嵌入SDAE步骤中 l 不是中间层或者输出层时，隐藏单元的数量；</li>
<li>$N_f$和$S_f$ 分别表示视觉嵌入的SCAE步骤中每个卷积层中滤波图的数量和大小。</li>
</ul>
<p>注意，为了保持协同过滤部分的不同分解方法，在以下小节中比较的基线的潜在维度与表2中的相同，基线的其他超参数由网格搜索确定。</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326153150856.png" alt="image-20210326153150856"><br>表2：我们两个数据集的框架的HyperParameter设置。 CF，SK，TK和VK指示协同过滤，结构知识嵌入，文本知识嵌入和视觉知识嵌入的组件中的参数。</p>
<p>在以下小节中，我们将根据四个方面评估拟议的框架。<br>首先，我们分别评估了关于结构知识使用，文本知识用法和视觉知识使用的推荐表现。<br>然后，我们将联合模型CKE与最先进的基线进行比较，以展示我们系统的有效性。</p>
<h3 id="6-2-3-4-图"><a href="#6-2-3-4-图" class="headerlink" title="6.2.3.4 图"></a>6.2.3.4 图</h3><p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326154132437.png" alt="image-20210326154132437"><br>图6：Recall@K值，我们的方法之间使用知识库中的每个组件与数据集Movielens-1M相关基线之间的方法之间的比较。</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326154205047.png" alt="image-20210326154205047"><br>图7：Map @ K结果，我们的方法在使用知识库中的每个组件之间的比较，以及数据集Movielens-1M的相关基线。</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326154249848.png" alt="image-20210326154249848"><br>图8：调用我们的方法之间使用知识库中的每个组件的方法与数据集Intentbook的相关基线之间的方法比较。</p>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326154403232.png" alt="image-20210326154403232"><br>图9：Map @ K结果我们在使用知识库中的每个组件与数据集目录中的每个组件之间的方法之间的比较。</p>
<h3 id="6-3-对于-结构化知识-的研究"><a href="#6-3-对于-结构化知识-的研究" class="headerlink" title="6.3 对于 结构化知识 的研究"></a>6.3 对于 结构化知识 的研究</h3><p>在本小节中，为了研究我们的结构知识使用的表现，我们<strong>只将结构知识嵌入组件纳入联合学习过程中的协同滤波中</strong>。我们将我们称为“CKE”的方法与以下基准进行比较：</p>
<ul>
<li>BPRMF：我们使用贝叶斯个性化排名的基于矩阵分解[22]，这是基于用户的成对偏好，作为<strong>单一协同过滤方法</strong>。与我们的方法CKE相比，该基线完全忽略了结构知识的使用。</li>
<li>BPRMF + Transe：此方法结合了BPRMF和网络嵌入方法，称为<strong>TransE</strong> [3]进行联合学习。此基线实际上使用与我们的方法CKE相同的设置，除了它使用TransE，忽略实体和关系的异构性，而不是TransR嵌入结构知识</li>
<li>PRP：具有前瞻统称的PageRank [17]将User-Item关系和结构知识集成到统一的同类图中，然后为每个用户执行PageRank，具有个性化的初始概率分布。</li>
<li>PER：个性化实体建议[30]将<strong>结构知识视为异构信息网络</strong>，并提取基于元路径的潜在特征，以表示用户和项目之间的连接沿不同类型的关系路径。在本文中，我们使用所有项目 - attributeItem格式的元路径特征（例如，“Movie-Penre-Movie”）。</li>
<li>LIBFM(S)：LIBFM [21]是基于最先进的功能的分解模型。在本文中，LIBFM(S)意味着我们<strong>在结构知识中使用项目的属性作为原始特征</strong>以馈入LIBFM。</li>
</ul>
<p>不同方法的结果在图6（a）中给出，图7（a），图8（a）和图9（a）。</p>
<p>结果汇集了两个数据集的几种观察，我们总结为：</p>
<p>1） BPRMF在所有方法中表现最差。由于BPRMF是完全忽略了结构知识的唯一一个，结果意味着结构知识的额外使用可以显着提高推荐性能。 </p>
<p>2）PRP表现比利用结构知识的其他方法更糟糕。这是因为其中，PRP是唯一不利用分解的唯一一个，这可以捕获数据集的稀疏度下的用户项目交互的潜在低逼近。 </p>
<p>3）BPRMF + TRANSE优于LIBFM和PER，它表明，而不是直接在特征工程方式中使用结构知识，网络嵌入可以以更合理的方式捕获语义表示，从而提高推荐质量。 </p>
<p>4）我们的方法CKE（s）击败BPRMF + Transe，这意味着通过使用Transr，在考虑网络嵌入的异质性时，仍有改进的余地。</p>
<h3 id="6-4-对于-文本化知识-的研究"><a href="#6-4-对于-文本化知识-的研究" class="headerlink" title="6.4 对于 文本化知识 的研究"></a>6.4 对于 文本化知识 的研究</h3><p>在本小节中，我们调查了我们的文本知识使用的表现。具体而言，我们在联合学习过程中使用文本知识嵌入组件和协同过滤。我们比较我们的方法，它被称为“CKE（T）”，反对BPRMF以及以下基准：</p>
<ul>
<li>LIBFM(T)：此方法与第6.3节中引入的libfm相同，除了文本知识中的词袋现在用作原始特征以进入libfm。</li>
<li>CMF(T)：集体矩阵分解[21]通过同时分解多个矩阵来组合不同类型的数据源。在本文中，CMF（t）意味着我们使用的两个矩阵是用户项矩阵和项目字矩阵。 </li>
<li>CTR：协作主题回归[28]，它是利用建议的文本信息的StateOf-ART方法，同时集成了协同过滤和主题建模。</li>
</ul>
<p>如图6（b）所示，图7（b），图8（b）和图9（b），结果的比较显示了以下观察结果：</p>
<p>1）CKE（s）优于CKE（T）和libfm（s）优于libfm（t），这意味着与结构知识相比，文本知识对推荐绩效的改善具有较弱。 </p>
<p>2）libfm（t），ctr和cke（t）通常提供比CMF更好的性能，这表明项目字矩阵的直接分解不能充分利用文本信息。 </p>
<p>3）CTR是一个强大的基线，有时甚至在IntentBooks数据集中实现最佳性能。然而，我们的方法CKE（t）可以大部分时间击败CTR，这表明与主题建模相比，深入学习嵌入通过深入地提取文本的语义表示来擅长提取文本的语义表示。</p>
<h3 id="6-5对于视觉知识的研究"><a href="#6-5对于视觉知识的研究" class="headerlink" title="6.5对于视觉知识的研究"></a>6.5对于视觉知识的研究</h3><p>在本小节中，我们专注于研究我们的视觉知识使用情况。如前所述，我们在联合学习中使用视觉知识嵌入组件和协作滤波。我们将我们的方法与BPRMF和以下基准命名为“CKE（v）”的方法：</p>
<ul>
<li>libfm（v）：此方法与第6.3节中的libfm相同，不同之处在于RGB颜色空间中的扁平原始像素表示作为原始功能。</li>
<li>CMF（v）：此方法使用与第6.4节中描述的CMF（T）相同的设置，不同之处在于我们使用用户项矩阵和项目 - 像素矩阵进行同时分解。</li>
<li>BPRMF + SDAE（V）：此方法使用与我们的方法CKE（v）相同的设置，除了它使用堆叠的去噪自动编码器来嵌入可视知识。这是为了评估卷积层是否对视觉知识嵌入有效。</li>
</ul>
<p>不同方法的结果如图6（c）所示，图7（c），图8（c）和图9（c），它为我们提供了以下观察：</p>
<p>1）与结构知识和文本知识相比，使用视觉知识的性能改善是有限的，但仍然很大。 </p>
<p>2）CKE（v）和BPRMF + SDAE（v）优于其他方法，这表明了深度网络的优越性，用于视觉知识嵌入。 </p>
<p>3）CKE（V）和BPRMF + SDAE（V）之间的性能差距仍然显着，这揭示了卷积层更适合提取视觉表示。</p>
<h3 id="6-6-对于整个框架的研究"><a href="#6-6-对于整个框架的研究" class="headerlink" title="6.6 对于整个框架的研究"></a>6.6 对于整个框架的研究</h3><p>最后，我们评估了我们整个框架的表现。我们使用知识库嵌入中的三个组件进行比较我们的终极模型，其表示为“CKE（STV）”，与以下基准显示：</p>
<ul>
<li>CKE（ST），CKE（SV），CKE（ST）：CKE（ST）使用与CKE（STV）相同的设置，除了它<strong>只包含结构知识和文本知识</strong>，这是为了评估视觉的额外使用情况知识是有效的。该定义类似于CKE（SV）和CKE（TV）。</li>
<li>Libfm（STV）：此方法使用与第6.4节中提到的Libfm相同的设置，除了结构知识，<strong>文本知识和视觉知识</strong>全部用作特征。 </li>
<li>BPRMF + STV：此方法使用与CKE（STV）相同的设置，除了<strong>它分别学习协同过滤和三个知识库嵌入组件</strong>。这是为了评估联合学习是否有效。</li>
</ul>
<p><img src="https://gitee.com/songx86/SongPicBed/raw/master/img/image-20210326153026266.png" alt="image-20210326153026266"><br>图10:Recall@K我们框架和相关基线之间的比较两个数据集。 图11:Map@K结果我们的框架与两个数据集相关基线之间比较。</p>
<p>结果如图10和图11所示，其给出了以下观察结果：</p>
<p>1）CKE（STV）优于CKE（ST），CKE（SV）和CKE（TV）。这意味着每种知识的额外使用可以提高推荐绩效，这表明我们框架与各种知识相结合的框架，以加强推荐。 </p>
<p>2）CKE（STV）优于Libfm（STV），它表明与专业工程方式中知识库的直接使用相比，嵌入组件可以更有效地捕获知识库的语义表示，从而提高推荐性能。 </p>
<p>3）CKE（STV）仍然比BPRMF + STV归档更好的性能，其表明，协同过滤和知识库嵌入的联合学习可以以更直接的方式针对推荐优化任务，从而提高建议质量。</p>
<h2 id="7-相关工作"><a href="#7-相关工作" class="headerlink" title="7 相关工作"></a>7 相关工作</h2><h3 id="7-1-知识库推荐"><a href="#7-1-知识库推荐" class="headerlink" title="7.1 知识库推荐"></a>7.1 知识库推荐</h3><p>近年来，在推荐系统的背景下的知识库的使用量正在吸引不断的关注。</p>
<p>例如，Cheekula等人。 [5]探索从修剪的DBPedia知识库导出的分层类别知识，并应用扩展激活算法将个性化实体识别为推荐。</p>
<p>Passant[18]计算知识库的图形结构中的语义距离，并使用该距离测量来构建音乐推荐系统。</p>
<p>与以前的作品相比，主要通过利用<strong>知识库的结构</strong>来研究这个问题，我们提出了一个框架，将异构知识从结构，文本以及视觉内容进行整合到推荐。</p>
<h3 id="7-2-结构化知识嵌入"><a href="#7-2-结构化知识嵌入" class="headerlink" title="7.2 结构化知识嵌入"></a>7.2 结构化知识嵌入</h3><p>以前的结构知识作品主要旨在将实体和关系嵌入到连续的矢量空间中，并模拟该空间中结构的语义。</p>
<p>例如，TransE [3]表示转换矢量的关系，使得三重嵌入实体可以以低误差连接。然而，TransE在对知识库中处理了对结构信息的异质性的多对多关系。</p>
<p>为了解决TransE的问题，TransR [15]提出实体和关系的步骤是完全不同的对象和模型实体以及在不同的空间中的关系，并通过使用翻译矩阵在关系空间中执行转换。</p>
<p>在本文中，我们将<strong>TransR与我们的推荐任务集成</strong>，以充分利用知识库中的结构知识。</p>
<h3 id="7-3-深度学习推荐算法"><a href="#7-3-深度学习推荐算法" class="headerlink" title="7.3 深度学习推荐算法"></a>7.3 深度学习推荐算法</h3><p>随着近年来深度学习的成功，有一个从事专业特征的标记开关，即从建议研究中从原始数据中学到的那些。</p>
<p>例如，Elkahky等人[8]提出了一种多视图深度学习模型，用于了解来自不同域的用户功能和项目特征，并使用丰富的功能表示来提高所有域的推荐质量。</p>
<p>王[29]通过共同表现为文本内容信息和评级矩阵的协作滤波来显着提高建议表现。</p>
<p>我们的框架在以下几个方面的上述作品中区分了本身：<br>1）我们专门应用<strong>堆叠的卷积自动编码器来提取视觉内容的语义表示</strong>，这些内容尚未在以前的作品中被利用。<br>2）我们通过整合协同过滤和结构，文本和视觉知识的异质性来设计一个<strong>联合模型</strong>，以提高推荐质量</p>
<h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8.总结"></a>8.总结</h2><p>本文提出了一个被称为CKE的混合推荐制度，该系统集成了协同过滤和知识库以供建议。</p>
<p>在此框架之后，我们首先设计三个组件，它利用异构网络嵌入和深度学习嵌入方法，分别从知识库中的结构知识，文本知识和视觉知识中自动提取语义表示。</p>
<p>接下来，我们将协同过滤和知识库嵌入组件与统一框架相结合，并共同学习不同的表示。</p>
<p>我们进行的广泛实验验证了我们CKE框架的有效性。</p>
<p>此外，这项研究揭示了<strong>知识库中的异构信息的使用</strong>，可以在更多的应用方案中用到。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">SongX64</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://SongX64.github.io/2021/03/19/0319%E5%B5%8C%E5%85%A5%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8D%8F%E4%BD%9C%E7%9F%A5%E8%AF%86%E5%BA%93/">https://SongX64.github.io/2021/03/19/0319%E5%B5%8C%E5%85%A5%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%8D%8F%E4%BD%9C%E7%9F%A5%E8%AF%86%E5%BA%93/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">SongX64</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/%E7%A7%91%E7%A0%94/">
                                    <span class="chip bg-color">科研</span>
                                </a>
                            
                                <a href="/tags/Knowledge-Graph/">
                                    <span class="chip bg-color">Knowledge Graph</span>
                                </a>
                            
                                <a href="/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/">
                                    <span class="chip bg-color">论文翻译</span>
                                </a>
                            
                                <a href="/tags/Recommendation/">
                                    <span class="chip bg-color">Recommendation</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2021/04/01/0401%E5%B0%86%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C%E7%94%A8%E4%BA%8E%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/6.jpg" class="responsive-img" alt="用于推荐系统的知识图卷积网络">
                        
                        <span class="card-title">用于推荐系统的知识图卷积网络</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            2019年论文，用于推荐系统的知识图卷积网络
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-04-01
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E7%A7%91%E7%A0%94/" class="post-category">
                                    科研
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E7%A7%91%E7%A0%94/">
                        <span class="chip bg-color">科研</span>
                    </a>
                    
                    <a href="/tags/Knowledge-Graph/">
                        <span class="chip bg-color">Knowledge Graph</span>
                    </a>
                    
                    <a href="/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/">
                        <span class="chip bg-color">论文翻译</span>
                    </a>
                    
                    <a href="/tags/Recommendation/">
                        <span class="chip bg-color">Recommendation</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/03/09/1225%E8%B6%85%E6%95%B0%E6%8D%AE%E9%9B%86%E5%AD%A6%E4%B9%A0/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/19.jpg" class="responsive-img" alt="超越数据集学习：用于自然语言处理的知识图增强神经网络">
                        
                        <span class="card-title">超越数据集学习：用于自然语言处理的知识图增强神经网络</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            超越数据集学习：用于自然语言处理的知识图增强神经网络，没太看懂，貌似是提出一个框架性的东西，还待精读
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-03-09
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E7%A7%91%E7%A0%94/" class="post-category">
                                    科研
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E7%A7%91%E7%A0%94/">
                        <span class="chip bg-color">科研</span>
                    </a>
                    
                    <a href="/tags/Knowledge-Graph/">
                        <span class="chip bg-color">Knowledge Graph</span>
                    </a>
                    
                    <a href="/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/">
                        <span class="chip bg-color">论文翻译</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="767683882"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2020-2021</span>
            
            <span id="year">2020</span>
            <a href="/about" target="_blank">SongX64</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
			<br>
				<a href="https://beian.miit.gov.cn/" target="_blank">鲁ICP备2021015839号-1</a>
				 | 
				<img src="/medias/icp.png" style="vertical-align: text-bottom;" />
		 		<a target="_blank" href="http://www.beian.gov.cn/portal/registerSystemInfo?recordcode=37083102000087">鲁公网安备 37083102000087号</a>
            </span>
			
		 
            <br>
            
            
            
            
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link ">
    <a href="https://github.com/SongX64" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:song.x64@gmail.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=song-x64@qq.com" class="tooltipped" target="_blank" data-tooltip="QQ联系我: song-x64@qq.com" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/shizuku.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script></body>

</html>
